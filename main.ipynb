{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support: True\n",
      "os              : Windows-10-10.0.19044-SP0\n",
      "python          : 3.9.16\n",
      "tsai            : 0.3.5\n",
      "fastai          : 2.7.11\n",
      "fastcore        : 1.5.28\n",
      "torch           : 1.13.1\n",
      "device          : 1 gpu (['NVIDIA GeForce GTX 970'])\n",
      "cpu cores       : 4\n",
      "threads per cpu : 1\n",
      "RAM             : 15.95 GB\n",
      "GPU memory      : [4.0] GB\n"
     ]
    }
   ],
   "source": [
    "#%pip install tsai\n",
    "#%pip install ta\n",
    "#%pip install optuna\n",
    "#%pip install sklearn\n",
    "#%pip install matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "from Preprocessing.preprocessing import preprocessing\n",
    "import time\n",
    "import torch\n",
    "from tsai.all import *\n",
    "import os\n",
    "from Optimizer.optimizer import optimize_model, optimize_data, get_binary_accuracy_clf\n",
    "from Evaluation.evaluation_tsai import calculate_pseudo_return, get_plots_classification, get_plots_regression\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import time\n",
    "\n",
    "print('GPU support:', torch.cuda.is_available())\n",
    "computer_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Data\\\\twelve_data\\AAPL_15min'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "index = file.split('\\\\')[-1].split('_')[-1]\n",
    "data = 'twelve' if 'twelve' in file else 'alpacca'\n",
    "\n",
    "preprocessing_params = {\n",
    "    'df': df[:3000],\n",
    "    'TSAI': True,\n",
    "    'CLF': False,\n",
    "    'index': index,\n",
    "    'data': data,\n",
    "    'sequence_length' : 30\n",
    "}\n",
    "\n",
    "model_type = \"mini_rocket\"\n",
    "folder = '100'\n",
    "Classifier = preprocessing_params['CLF']\n",
    "model_type = model_type + '_class' if Classifier else model_type + '_reg'\n",
    "\n",
    "data_opti = False\n",
    "if data_opti:\n",
    "    optimize_data(model_type=model_type, preprocessing_params=preprocessing_params, n_trials=50, n_epochs=20, batch_size = 64, index = preprocessing_params.pop('index', None))\n",
    "\n",
    "    def get_results(df, groupby_col):\n",
    "        agg_results = df.groupby(groupby_col).agg({'bin_accuracy': ['mean', 'max', 'min', 'count']}).reset_index()\n",
    "        agg_results.columns = [groupby_col, 'Mean', 'High', 'Low', 'Count']\n",
    "        agg_results = agg_results.sort_values(by='Mean', ascending=False)\n",
    "        return agg_results\n",
    "\n",
    "    if folder == '100':\n",
    "        df = pd.read_csv(f\"Optimizer/data_optimization/{model_type}/{100}/{model_type}_{index}_100_hyperparameters_results.csv\").fillna('None')\n",
    "    else:\n",
    "        df = pd.read_csv(f\"Optimizer/data_optimization/{model_type}/{100}/{model_type}_{index}_hyperparameters_results.csv\").fillna('None')\n",
    "        \n",
    "    groupby_cols = ['lag', 'dif_all', 'train_size', 'buckets', 'TI']\n",
    "    results = {col: get_results(df, col) for col in groupby_cols}\n",
    "\n",
    "    for col in groupby_cols:\n",
    "        print(f\"Results for {col}:\")\n",
    "        print(results[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>df_len</th>\n",
       "      <th>epochs</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>d_model</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_heads</th>\n",
       "      <th>d_ff</th>\n",
       "      <th>dropout</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.68</td>\n",
       "      <td>193.279337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.67</td>\n",
       "      <td>443.434187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>402.844881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>512</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>322.990533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>307.735555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.41</td>\n",
       "      <td>575.344904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>196.971211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.37</td>\n",
       "      <td>681.632344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2024.184410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tst_class</td>\n",
       "      <td>199961</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>130.980736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  df_len  epochs  seq_length  batch_size  learning_rate  d_model  \\\n",
       "24  tst_class  199961      20          30         128         0.0001      512   \n",
       "19  tst_class  199961      20          30         128         0.0001      512   \n",
       "73  tst_class  199961      20          30         128         0.0001      512   \n",
       "67  tst_class  199961      20          30         128         0.0010      512   \n",
       "85  tst_class  199961      20          20         128         0.0001      512   \n",
       "..        ...     ...     ...         ...         ...            ...      ...   \n",
       "79  tst_class  199961      20          10         128         0.0001      512   \n",
       "45  tst_class  199961      20          30         128         0.0001      512   \n",
       "7   tst_class  199961      20          40          64         0.0010       64   \n",
       "93  tst_class  199961      20          30         128         0.0001      512   \n",
       "75  tst_class  199961      20          30         128         0.0100      512   \n",
       "\n",
       "    n_layers  n_heads  d_ff  dropout  val_accuracy         time  \n",
       "24         1        8   512      0.4          0.68   193.279337  \n",
       "19         1        8   512      0.6          0.67   443.434187  \n",
       "73         1        8   512      0.4          0.65   402.844881  \n",
       "67         1       16   512      0.2          0.65   322.990533  \n",
       "85         2        8   512      0.4          0.65   307.735555  \n",
       "..       ...      ...   ...      ...           ...          ...  \n",
       "79         4        8   512      0.4          0.41   575.344904  \n",
       "45         1        8   512      0.4          0.39   196.971211  \n",
       "7          8       32   256      0.2          0.37   681.632344  \n",
       "93         8        8   512      0.4          0.32  2024.184410  \n",
       "75         1        8   512      0.4          0.28   130.980736  \n",
       "\n",
       "[99 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Optimizer.optimizer import optimize_model\n",
    "\n",
    "amazon = False\n",
    "if amazon:\n",
    "    file = 'Data\\\\twelve_data\\AAPL_1min'\n",
    "    index = file.split('\\\\')[-1].split('_')[-1]\n",
    "else:\n",
    "    file = 'Data/twelve_data/AAPL_1min'\n",
    "    index = file.split('/')[-1].split('_')[-1]\n",
    "\n",
    "data = 'twelve' if 'twelve' in file else 'alpacca'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "preprocessing_params = {\n",
    "    'df': df,\n",
    "    'lag': 15,\n",
    "    'dif_all': True,\n",
    "    'train_size': 0.95,\n",
    "    'TSAI': True,\n",
    "    'CLF': True,\n",
    "    'index': None,\n",
    "    'data': data,\n",
    "    'buckets': 10,\n",
    "    'TI' : True\n",
    "}\n",
    "\n",
    "model_type = 'tst'\n",
    "folder = '100'\n",
    "Classifier = preprocessing_params['CLF']\n",
    "model_type = model_type + '_class' if Classifier else model_type + '_reg'\n",
    "\n",
    "opti = False\n",
    "if opti:\n",
    "    optimize_model(model_type=model_type, preprocessing_params=preprocessing_params, n_trials=1, n_epochs=1, folder=folder, index_time = index)\n",
    "\n",
    "results_df = pd.read_csv(f\"models/{model_type}/{folder}/{index}/{model_type}_hyperparameters_results.csv\")\n",
    "\n",
    "if Classifier: \n",
    "    df = results_df.sort_values(by='val_accuracy', ascending=False)\n",
    "else: \n",
    "    df = results_df.sort_values(by='val_mae', ascending=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose model and its optimal data and hyperparameter and preprocesses it and trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/test_sets/1min/BTCUSD_1min\n",
      "Data/test_sets/1min/CHGG_1min\n",
      "Data/test_sets/1min/CRM_1min\n",
      "Data/test_sets/1min/ETHUSD_1min\n",
      "Data/test_sets/1min/GLD_1min\n",
      "Data/test_sets/1min/LOGI_1min\n",
      "Data/test_sets/1min/UNG_1min\n",
      "Data/test_sets/1min/USDTUSD_1min\n",
      "Data/test_sets/1min/USO_1min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-12 15:38:00</td>\n",
       "      <td>39.885</td>\n",
       "      <td>39.895</td>\n",
       "      <td>39.8800</td>\n",
       "      <td>39.895</td>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-12 15:39:00</td>\n",
       "      <td>39.890</td>\n",
       "      <td>39.895</td>\n",
       "      <td>39.8900</td>\n",
       "      <td>39.890</td>\n",
       "      <td>6603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-12 15:40:00</td>\n",
       "      <td>39.890</td>\n",
       "      <td>39.895</td>\n",
       "      <td>39.8850</td>\n",
       "      <td>39.885</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-12 15:41:00</td>\n",
       "      <td>39.885</td>\n",
       "      <td>39.905</td>\n",
       "      <td>39.8850</td>\n",
       "      <td>39.900</td>\n",
       "      <td>7420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12 15:42:00</td>\n",
       "      <td>39.910</td>\n",
       "      <td>39.915</td>\n",
       "      <td>39.9100</td>\n",
       "      <td>39.915</td>\n",
       "      <td>7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194957</th>\n",
       "      <td>2023-03-01 15:55:00</td>\n",
       "      <td>68.040</td>\n",
       "      <td>68.040</td>\n",
       "      <td>68.0300</td>\n",
       "      <td>68.040</td>\n",
       "      <td>17596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194958</th>\n",
       "      <td>2023-03-01 15:56:00</td>\n",
       "      <td>68.035</td>\n",
       "      <td>68.045</td>\n",
       "      <td>68.0301</td>\n",
       "      <td>68.040</td>\n",
       "      <td>7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194959</th>\n",
       "      <td>2023-03-01 15:57:00</td>\n",
       "      <td>68.050</td>\n",
       "      <td>68.060</td>\n",
       "      <td>68.0400</td>\n",
       "      <td>68.045</td>\n",
       "      <td>39688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194960</th>\n",
       "      <td>2023-03-01 15:58:00</td>\n",
       "      <td>68.040</td>\n",
       "      <td>68.050</td>\n",
       "      <td>68.0200</td>\n",
       "      <td>68.050</td>\n",
       "      <td>26084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194961</th>\n",
       "      <td>2023-03-01 15:59:00</td>\n",
       "      <td>68.050</td>\n",
       "      <td>68.060</td>\n",
       "      <td>68.0400</td>\n",
       "      <td>68.060</td>\n",
       "      <td>42066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194962 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime    open    high      low   close  volume\n",
       "0       2021-02-12 15:38:00  39.885  39.895  39.8800  39.895    6250\n",
       "1       2021-02-12 15:39:00  39.890  39.895  39.8900  39.890    6603\n",
       "2       2021-02-12 15:40:00  39.890  39.895  39.8850  39.885    4460\n",
       "3       2021-02-12 15:41:00  39.885  39.905  39.8850  39.900    7420\n",
       "4       2021-02-12 15:42:00  39.910  39.915  39.9100  39.915    7109\n",
       "...                     ...     ...     ...      ...     ...     ...\n",
       "194957  2023-03-01 15:55:00  68.040  68.040  68.0300  68.040   17596\n",
       "194958  2023-03-01 15:56:00  68.035  68.045  68.0301  68.040    7135\n",
       "194959  2023-03-01 15:57:00  68.050  68.060  68.0400  68.045   39688\n",
       "194960  2023-03-01 15:58:00  68.040  68.050  68.0200  68.050   26084\n",
       "194961  2023-03-01 15:59:00  68.050  68.060  68.0400  68.060   42066\n",
       "\n",
       "[194962 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sets_dir = 'Data/test_sets/1min/'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(test_sets_dir)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in files:\n",
    "    # Load the file into a pandas dataframe\n",
    "    path = os.path.join(test_sets_dir, file)\n",
    "    print(path)\n",
    "    df = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/test_sets/5min/BTCUSD_5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock:, BTCUSD  Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock:, BTCUSD  Accuracy: 0.53\n",
      "Data/test_sets/5min/CHGG_5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock:, CHGG  Accuracy: 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock:, CHGG  Accuracy: 0.48\n",
      "Data/test_sets/5min/CRM_5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     81\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 82\u001b[0m learner\u001b[39m.\u001b[39;49mfit_one_cycle(n_epoch \u001b[39m=\u001b[39;49m epochs, lr_max\u001b[39m=\u001b[39;49mlearning_rate)\n\u001b[0;32m     83\u001b[0m training_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\n\u001b[0;32m     85\u001b[0m acc \u001b[39m=\u001b[39m get_binary_accuracy_clf(learner, X[splits[\u001b[39m1\u001b[39m]], y[splits[\u001b[39m1\u001b[39m]], preprocessing_params[\u001b[39m'\u001b[39m\u001b[39mbuckets\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\callback\\schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    116\u001b[0m lr_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([h[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mhypers])\n\u001b[0;32m    117\u001b[0m scheds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[39m/\u001b[39mdiv, lr_max, lr_max\u001b[39m/\u001b[39mdiv_final),\n\u001b[0;32m    118\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mmom\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, \u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoms \u001b[39mif\u001b[39;00m moms \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m moms))}\n\u001b[1;32m--> 119\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mParamScheduler(scheds)\u001b[39m+\u001b[39;49mL(cbs), reset_opt\u001b[39m=\u001b[39;49mreset_opt, wd\u001b[39m=\u001b[39;49mwd, start_epoch\u001b[39m=\u001b[39;49mstart_epoch)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lr)\n\u001b[0;32m    263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch \u001b[39m=\u001b[39m n_epoch\n\u001b[1;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelFitException, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_end_cleanup)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch):\n\u001b[0;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m=\u001b[39mepoch\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch, \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelEpochException)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 247\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_train()\n\u001b[0;32m    248\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch_train\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    238\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mtrain\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelTrainException)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_batch(\u001b[39m*\u001b[39;49mo)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\tsai\\learner.py:40\u001b[0m, in \u001b[0;36mone_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m     38\u001b[0m b_on_device \u001b[39m=\u001b[39m to_device(b, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mdevice) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m b\n\u001b[0;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(b_on_device)\n\u001b[1;32m---> 40\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one_batch, \u001b[39m'\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBatchException)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:219\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39mself\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mafter_pred\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39myb):\n\u001b[1;32m--> 219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49myb)\n\u001b[0;32m    220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_grad\u001b[39m.\u001b[39mclone()\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mafter_loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\losses.py:54\u001b[0m, in \u001b[0;36mBaseLoss.__call__\u001b[1;34m(self, inp, targ, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mif\u001b[39;00m targ\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m [torch\u001b[39m.\u001b[39mint8, torch\u001b[39m.\u001b[39mint16, torch\u001b[39m.\u001b[39mint32]: targ \u001b[39m=\u001b[39m targ\u001b[39m.\u001b[39mlong()\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten: inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,inp\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_2d \u001b[39melse\u001b[39;00m inp\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inp, targ\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten \u001b[39melse\u001b[39;00m targ, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\losses.py:205\u001b[0m, in \u001b[0;36mLabelSmoothingCrossEntropy.forward\u001b[1;34m(self, output, target)\u001b[0m\n\u001b[0;32m    203\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mlog_preds\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m#We divide by that size at the return line so sum and not mean\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:  loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()\n\u001b[1;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps\u001b[39m/\u001b[39mc \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps) \u001b[39m*\u001b[39m F\u001b[39m.\u001b[39mnll_loss(log_preds, target\u001b[39m.\u001b[39mlong(), weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreduction)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "\n",
    "test_sets_dir = 'Data/test_sets/5min/'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(test_sets_dir)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in files:\n",
    "    #Load the file into a pandas dataframe\n",
    "    path = os.path.join(test_sets_dir, file)\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    stock = file.split('/')[-1].split('_')[-2]\n",
    "\n",
    "    trials = 10\n",
    "    for _ in range(trials):\n",
    "\n",
    "        # Set the random seed for reproducibility\n",
    "        seed += 1\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "\n",
    "        model_type = 'lstm_class'\n",
    "\n",
    "        preprocessing_params = {\n",
    "            'df': df,\n",
    "            'lag': 1,\n",
    "            'dif_all': False,\n",
    "            'train_size': 0.95, #Will be adjusted in code\n",
    "            'TSAI': True, #Always true\n",
    "            'CLF': True, #Always true\n",
    "            'index': None,\n",
    "            'data': 'twelve',\n",
    "            'buckets': 3,\n",
    "            'TI' : True\n",
    "        }\n",
    "\n",
    "        model_params = {\n",
    "            'seq_length':50, \n",
    "            'batch_size':128, \n",
    "            'learning_rate':0.01, \n",
    "            'hidden_size':100, \n",
    "            'n_layers':8, \n",
    "            'rnn_dropout':0.6, \n",
    "            'fc_dropout':0.6\n",
    "        } #Adjust based on model, should be a dict\n",
    "\n",
    "        seq_length = model_params.pop('seq_length', None)\n",
    "        batch_size = model_params.pop('batch_size', None)\n",
    "        learning_rate = model_params.pop('learning_rate', None)\n",
    "\n",
    "        data_train,data_test, _ = preprocessing(**preprocessing_params, sequence_length=seq_length, print_info=False)\n",
    "\n",
    "        # Changes the data into features and labels with the split used later in TSAI for modelling\n",
    "        test_points = 100\n",
    "        X, y, splits = combine_split_data([data_train[0], data_test[0][:test_points]],[data_train[1], data_test[1][:test_points]])\n",
    "\n",
    "        # Utilizes the GPU if possible\n",
    "        if torch.cuda.is_available(): X, y = X.cuda(), y.cuda()\n",
    "\n",
    "        dsets = TSDatasets(X, y, splits=splits)\n",
    "        dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=batch_size)\n",
    "\n",
    "        nr_features = X.shape[1] # Number of features\n",
    "        nr_labels = torch.unique(y).numel() if Classifier else 1 # Number of labels\n",
    "\n",
    "        # Initiates the models\n",
    "        if model_type == 'lstm_class' or model_type == 'lstm_reg': model = LSTMPlus(c_in=nr_features, c_out=nr_labels, **model_params)\n",
    "        if model_type == 'lstm_fcn_class' or model_type == 'lstm_fcn_reg': model = LSTM_FCNPlus(c_in=nr_features, c_out=nr_labels, **model_params, shuffle=False)\n",
    "        if model_type == 'tst_class' or model_type == 'tst_reg': model = TST(c_in=nr_features, c_out=nr_labels, seq_len=seq_length, **model_params)\n",
    "        #if model_type == 'mini_rocket': model = \n",
    "\n",
    "        learner = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=accuracy, cbs=[EarlyStoppingCallback(patience=5)])\n",
    "\n",
    "        # Trains the model\n",
    "        epochs = 20\n",
    "        start = time.time()\n",
    "        learner.fit_one_cycle(n_epoch = epochs, lr_max=learning_rate)\n",
    "        training_time = time.time() - start\n",
    "\n",
    "        acc = get_binary_accuracy_clf(learner, X[splits[1]], y[splits[1]], preprocessing_params['buckets'])\n",
    "\n",
    "        # Add the results to the pandas dataframe\n",
    "        results_df = pd.read_csv('Results/prediction_results.csv') if os.path.exists('Results/prediction_results.csv') else pd.DataFrame(columns=['Model', 'Stock', 'Accuracy', 'Time'])\n",
    "        results_df = results_df.append({\n",
    "            'Model': model_type,\n",
    "            'Stock': stock,\n",
    "            'Accuracy': acc,\n",
    "            'Time': training_time\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        # Save the dataframe to a csv file\n",
    "        results_df.to_csv('Results/prediction_results.csv', index=False)\n",
    "\n",
    "        print('Stock:,', stock, ' Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if torch.cuda.isavailable(): X, y = X.cpu(), y.cpu()\n",
    "\n",
    "#get_plots_classification(learner = learner, X = X, y = y, splits = splits, buckets = preprocessing_params[\"buckets\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68687a499e0775bfb06d4a0c91954dfe7dcdc7f84c6d272d4d4615fc1c039e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
