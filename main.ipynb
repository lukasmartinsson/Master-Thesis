{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU support: True\n",
      "os              : Windows-10-10.0.19044-SP0\n",
      "python          : 3.9.16\n",
      "tsai            : 0.3.5\n",
      "fastai          : 2.7.11\n",
      "fastcore        : 1.5.28\n",
      "torch           : 1.13.1\n",
      "device          : 1 gpu (['NVIDIA GeForce GTX 970'])\n",
      "cpu cores       : 4\n",
      "threads per cpu : 1\n",
      "RAM             : 15.95 GB\n",
      "GPU memory      : [4.0] GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Preprocessing.preprocessing import preprocessing\n",
    "import time\n",
    "import torch\n",
    "from tsai.all import *\n",
    "\n",
    "print('GPU support:', torch.cuda.is_available())\n",
    "computer_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-17 12:03:08,205]\u001b[0m A new study created in memory with name: no-name-be9f8baa-1e4e-45e3-92a4-438578ba9b55\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "torch.Size([699, 9, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-03-17 12:03:59,382]\u001b[0m Trial 0 failed with parameters: {'seq_length': 300, 'batch_size': 16, 'learning_rate': 1.3336466469356106e-06, 'd_model': 256, 'n_layers': 8, 'n_heads': 32, 'd_ff': 1024, 'dropout': 0.2} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"c:\\Users\\lukas\\Programmering\\Investment AI\\Master-Thesis\\Optimizer\\optimizer.py\", line 110, in objective\n",
      "    learn.fit_one_cycle(15, lr_max=learning_rate)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\callback\\schedule.py\", line 119, in fit_one_cycle\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 264, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 253, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 248, in _do_epoch\n",
      "    self._do_epoch_validate()\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 244, in _do_epoch_validate\n",
      "    with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 199, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 205, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\tsai\\learner.py\", line 40, in one_batch\n",
      "    self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 201, in _with_events\n",
      "    self(f'after_{event_type}');  final()\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 172, in __call__\n",
      "    def __call__(self, event_name): L(event_name).map(self._call_one)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastcore\\foundation.py\", line 156, in map\n",
      "    def map(self, f, *args, **kwargs): return self._new(map_ex(self, f, *args, gen=False, **kwargs))\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastcore\\basics.py\", line 840, in map_ex\n",
      "    return list(res)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastcore\\basics.py\", line 825, in __call__\n",
      "    return self.func(*fargs, **kwargs)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 176, in _call_one\n",
      "    for cb in self.cbs.sorted('order'): cb(event_name)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\callback\\core.py\", line 60, in __call__\n",
      "    try: res = getcallable(self, event_name)()\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 560, in after_batch\n",
      "    for met in mets: met.accumulate(self.learn)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py\", line 482, in accumulate\n",
      "    self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\metrics.py\", line 105, in accuracy\n",
      "    pred,targ = flatten_check(inp.argmax(dim=axis), targ)\n",
      "  File \"c:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\torch_core.py\", line 756, in flatten_check\n",
      "    inp,targ = TensorBase(inp.contiguous()).view(-1),TensorBase(targ.contiguous()).view(-1)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-03-17 12:03:59,387]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m opti \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m opti:\n\u001b[1;32m---> 21\u001b[0m     optimize_model(model_type\u001b[39m=\u001b[39;49mmodel_type, preprocessing_params\u001b[39m=\u001b[39;49mpreprocessing_params, n_trials\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m{\u001b[39;00mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m_hyperparameters_results.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m results_df\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Programmering\\Investment AI\\Master-Thesis\\Optimizer\\optimizer.py:177\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m(model_type, preprocessing_params, n_trials)\u001b[0m\n\u001b[0;32m    174\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(study_name\u001b[39m=\u001b[39mstudy_name, storage\u001b[39m=\u001b[39mstorage_name, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    176\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 177\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mn_trials)\n\u001b[0;32m    179\u001b[0m \u001b[39m# Save the best parameters\u001b[39;00m\n\u001b[0;32m    180\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[1;32mc:\\Users\\lukas\\Programmering\\Investment AI\\Master-Thesis\\Optimizer\\optimizer.py:110\u001b[0m, in \u001b[0;36moptimize_model.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    107\u001b[0m learn \u001b[39m=\u001b[39m Learner(dls, model, loss_func\u001b[39m=\u001b[39mLabelSmoothingCrossEntropyFlat(), metrics\u001b[39m=\u001b[39maccuracy)\n\u001b[0;32m    109\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers([learn\u001b[39m.\u001b[39mno_logging(), learn\u001b[39m.\u001b[39mno_bar()]): \u001b[39m# [Optional] this prevents fastai from printing anything during training\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     learn\u001b[39m.\u001b[39;49mfit_one_cycle(\u001b[39m15\u001b[39;49m, lr_max\u001b[39m=\u001b[39;49mlearning_rate)\n\u001b[0;32m    112\u001b[0m \u001b[39m# Get the validation accuracy of the last epoch\u001b[39;00m\n\u001b[0;32m    113\u001b[0m val_accuracy \u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mvalues[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\callback\\schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[1;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    116\u001b[0m lr_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([h[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mhypers])\n\u001b[0;32m    117\u001b[0m scheds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[39m/\u001b[39mdiv, lr_max, lr_max\u001b[39m/\u001b[39mdiv_final),\n\u001b[0;32m    118\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mmom\u001b[39m\u001b[39m'\u001b[39m: combined_cos(pct_start, \u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoms \u001b[39mif\u001b[39;00m moms \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m moms))}\n\u001b[1;32m--> 119\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(n_epoch, cbs\u001b[39m=\u001b[39;49mParamScheduler(scheds)\u001b[39m+\u001b[39;49mL(cbs), reset_opt\u001b[39m=\u001b[39;49mreset_opt, wd\u001b[39m=\u001b[39;49mwd, start_epoch\u001b[39m=\u001b[39;49mstart_epoch)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[1;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mset_hypers(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39mif\u001b[39;00m lr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m lr)\n\u001b[0;32m    263\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch \u001b[39m=\u001b[39m n_epoch\n\u001b[1;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit, \u001b[39m'\u001b[39;49m\u001b[39mfit\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelFitException, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_end_cleanup)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epoch):\n\u001b[0;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m=\u001b[39mepoch\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch, \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelEpochException)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:248\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_epoch\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_epoch_train()\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_epoch_validate()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:244\u001b[0m, in \u001b[0;36mLearner._do_epoch_validate\u001b[1;34m(self, ds_idx, dl)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m dl \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: dl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls[ds_idx]\n\u001b[0;32m    243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl \u001b[39m=\u001b[39m dl\n\u001b[1;32m--> 244\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_batches, \u001b[39m'\u001b[39;49m\u001b[39mvalidate\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelValidException)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_with_events\u001b[39m(\u001b[39mself\u001b[39m, f, event_type, ex, final\u001b[39m=\u001b[39mnoop):\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m     \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mall_batches\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl)\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl): \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mone_batch(\u001b[39m*\u001b[39;49mo)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\tsai\\learner.py:40\u001b[0m, in \u001b[0;36mone_batch\u001b[1;34m(self, i, b)\u001b[0m\n\u001b[0;32m     38\u001b[0m b_on_device \u001b[39m=\u001b[39m to_device(b, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mdevice) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdls\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m b\n\u001b[0;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split(b_on_device)\n\u001b[1;32m---> 40\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_with_events(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_one_batch, \u001b[39m'\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m'\u001b[39;49m, CancelBatchException)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:201\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[1;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbefore_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m);  f()\n\u001b[0;32m    200\u001b[0m \u001b[39mexcept\u001b[39;00m ex: \u001b[39mself\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter_cancel_\u001b[39m\u001b[39m{\u001b[39;00mevent_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 201\u001b[0m \u001b[39mself\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mafter_\u001b[39;49m\u001b[39m{\u001b[39;49;00mevent_type\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m);  final()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:172\u001b[0m, in \u001b[0;36mLearner.__call__\u001b[1;34m(self, event_name)\u001b[0m\n\u001b[1;32m--> 172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, event_name): L(event_name)\u001b[39m.\u001b[39;49mmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastcore\\foundation.py:156\u001b[0m, in \u001b[0;36mL.map\u001b[1;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m--> 156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(map_ex(\u001b[39mself\u001b[39m, f, \u001b[39m*\u001b[39margs, gen\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastcore\\basics.py:840\u001b[0m, in \u001b[0;36mmap_ex\u001b[1;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(g, iterable)\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m gen: \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m--> 840\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(res)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastcore\\basics.py:825\u001b[0m, in \u001b[0;36mbind.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v,_Arg): kwargs[k] \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mpop(v\u001b[39m.\u001b[39mi)\n\u001b[0;32m    824\u001b[0m fargs \u001b[39m=\u001b[39m [args[x\u001b[39m.\u001b[39mi] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, _Arg) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpargs] \u001b[39m+\u001b[39m args[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 825\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39mfargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:176\u001b[0m, in \u001b[0;36mLearner._call_one\u001b[1;34m(self, event_name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_one\u001b[39m(\u001b[39mself\u001b[39m, event_name):\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(event, event_name): \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmissing \u001b[39m\u001b[39m{\u001b[39;00mevent_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 176\u001b[0m     \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcbs\u001b[39m.\u001b[39msorted(\u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m): cb(event_name)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\callback\\core.py:60\u001b[0m, in \u001b[0;36mCallback.__call__\u001b[1;34m(self, event_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun \u001b[39mand\u001b[39;00m _run: \n\u001b[1;32m---> 60\u001b[0m     \u001b[39mtry\u001b[39;00m: res \u001b[39m=\u001b[39m getcallable(\u001b[39mself\u001b[39;49m, event_name)()\n\u001b[0;32m     61\u001b[0m     \u001b[39mexcept\u001b[39;00m (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e: \u001b[39mraise\u001b[39;00m modify_exception(e, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mException occured in `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` when calling event `\u001b[39m\u001b[39m{\u001b[39;00mevent_name\u001b[39m}\u001b[39;00m\u001b[39m`:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:560\u001b[0m, in \u001b[0;36mRecorder.after_batch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39myb) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    559\u001b[0m mets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_mets \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_mets\n\u001b[1;32m--> 560\u001b[0m \u001b[39mfor\u001b[39;00m met \u001b[39min\u001b[39;00m mets: met\u001b[39m.\u001b[39;49maccumulate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearn)\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining: \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mhypers[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\learner.py:482\u001b[0m, in \u001b[0;36mAvgMetric.accumulate\u001b[1;34m(self, learn)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccumulate\u001b[39m(\u001b[39mself\u001b[39m, learn):\n\u001b[0;32m    481\u001b[0m     bs \u001b[39m=\u001b[39m find_bs(learn\u001b[39m.\u001b[39myb)\n\u001b[1;32m--> 482\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m learn\u001b[39m.\u001b[39mto_detach(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(learn\u001b[39m.\u001b[39;49mpred, \u001b[39m*\u001b[39;49mlearn\u001b[39m.\u001b[39;49myb))\u001b[39m*\u001b[39mbs\n\u001b[0;32m    483\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m bs\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\metrics.py:105\u001b[0m, in \u001b[0;36maccuracy\u001b[1;34m(inp, targ, axis)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maccuracy\u001b[39m(inp, targ, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompute accuracy with `targ` when `pred` is bs * n_classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 105\u001b[0m     pred,targ \u001b[39m=\u001b[39m flatten_check(inp\u001b[39m.\u001b[39;49margmax(dim\u001b[39m=\u001b[39;49maxis), targ)\n\u001b[0;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m (pred \u001b[39m==\u001b[39m targ)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\envs\\ai\\lib\\site-packages\\fastai\\torch_core.py:756\u001b[0m, in \u001b[0;36mflatten_check\u001b[1;34m(inp, targ)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflatten_check\u001b[39m(inp, targ):\n\u001b[0;32m    755\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCheck that `inp` and `targ` have the same number of elements and flatten them.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 756\u001b[0m     inp,targ \u001b[39m=\u001b[39m TensorBase(inp\u001b[39m.\u001b[39;49mcontiguous())\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m),TensorBase(targ\u001b[39m.\u001b[39mcontiguous())\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    757\u001b[0m     test_eq(\u001b[39mlen\u001b[39m(inp), \u001b[39mlen\u001b[39m(targ))\n\u001b[0;32m    758\u001b[0m     \u001b[39mreturn\u001b[39;00m inp,targ\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Optimizer.optimizer import optimize_model\n",
    "\n",
    "df = pd.read_csv('Data\\Stock\\StockBars\\MSFT_Minute')\n",
    " \n",
    "preprocessing_params = {\n",
    "    'df': df[:1000],\n",
    "    'lag': 1,\n",
    "    'dif_all': True,\n",
    "    'train_size': 0.8,\n",
    "    'TSAI': True,\n",
    "    'CLF': True,\n",
    "    'index': None,\n",
    "    'data': \"alpacca\",\n",
    "    'buckets': 1\n",
    "}\n",
    "\n",
    "model_type = 'tst_class'\n",
    "\n",
    "opti = True\n",
    "if opti:\n",
    "    optimize_model(model_type=model_type, preprocessing_params=preprocessing_params, n_trials=2)\n",
    "\n",
    "results_df = pd.read_csv(f\"models/{model_type}/{model_type}_hyperparameters_results.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_length': 200,\n",
       " 'batch_size': 16,\n",
       " 'hidden_size': 25,\n",
       " 'n_layers': 1,\n",
       " 'rnn_dropout': 0.5,\n",
       " 'fc_dropout': 0.4,\n",
       " 'learning_rate': 0.0019302736528178678}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'lstm_class'\n",
    "\n",
    "with open(f\"models/{model_type}/{model_type}_best_params.json\", \"r\") as f:\n",
    "    best_params = json.load(f)\n",
    "\n",
    "best_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a stock for Machine Learning Model Training and preprocesses it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label  Count  Train count  Test count  Bucket min  Bucket max\n",
      "0    0.0    432          338          93     -1.0488     -0.0001\n",
      "1    1.0    566          460         106      0.0000      0.9588\n",
      "2  Total    998          798         199     -1.0488      0.9588\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data using a custom function and split it into training and testing sets\n",
    "# Only the training and testing sets are used, so the third variable (a scalar) is discarded using an underscore\n",
    "\n",
    "seq_length = best_params.pop('seq_length', None)\n",
    "data_train, data_test, _ = preprocessing(**preprocessing_params, sequence_length=seq_length, print_info=True)\n",
    "\n",
    "# Changes the data into features and labels with the split used later in TSAI for modelling\n",
    "X, y, splits = combine_split_data([data_train[0], data_test[0]],[data_train[1], data_test[1]])\n",
    "\n",
    "# Utilizes the GPU if possible\n",
    "if torch.cuda.is_available(): X, y = X.cuda(), y.cuda()\n",
    "\n",
    "batch_size = best_params.pop('batch_size', None)\n",
    "dsets = TSDatasets(X, y, splits=splits)\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=batch_size)\n",
    "\n",
    "# Note this tabel is before sequenceing so the actuall values is total - sequence then times train_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes the models and learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model_params \u001b[39m=\u001b[39m {key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m best_params\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mseq_length\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m)}\n\u001b[0;32m      6\u001b[0m \u001b[39m# Initiates the models\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model_lstm_fcn \u001b[39m=\u001b[39m LSTM_FCNPlus(c_in\u001b[39m=\u001b[39mnr_features, c_out\u001b[39m=\u001b[39mnr_labels, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_params, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[39m#model_lstm = LSTMPlus(c_in=nr_features, c_out=nr_labels, seq_len=sequence_length)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#model_tst = TST(c_in=nr_features, c_out=nr_labels, seq_len=sequence_length)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m#model_xcm = XCMPlus(c_in=nr_features, c_out=nr_labels, seq_len=sequence_length)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m models \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mLSTM_FCNPlus\u001b[39m\u001b[39m'\u001b[39m: model_lstm_fcn}\u001b[39m#, 'LSTMPlus': model_lstm, 'TST': model_tst, 'XCMPlus': model_xcm}\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_layers'"
     ]
    }
   ],
   "source": [
    "nr_features = X.shape[1] # Number of features\n",
    "nr_labels = torch.unique(y).numel() # Number of labels\n",
    "\n",
    "model_params = {key: value for key, value in best_params.items() if key not in ('seq_length', 'batch_size', 'learning_rate')}\n",
    "\n",
    "# Initiates the models\n",
    "model_lstm_fcn = LSTM_FCNPlus(c_in=nr_features, c_out=nr_labels, **model_params, shuffle=False)\n",
    "#model_lstm = LSTMPlus(c_in=nr_features, c_out=nr_labels, seq_len=sequence_length)\n",
    "#model_tst = TST(c_in=nr_features, c_out=nr_labels, seq_len=sequence_length)\n",
    "#model_xcm = XCMPlus(c_in=nr_features, c_out=nr_labels, seq_len=sequence_length)\n",
    "\n",
    "models = {'LSTM_FCNPlus': model_lstm_fcn}#, 'LSTMPlus': model_lstm, 'TST': model_tst, 'XCMPlus': model_xcm}\n",
    "\n",
    "# Create Learner objects\n",
    "binary_classification_metrics = [accuracy]\n",
    "\n",
    "learn_lstm_fcn = Learner(dls, model_lstm_fcn, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=accuracy)\n",
    "#learn_lstm = Learner(dls, model_lstm, loss_func=LabelSmoothingCrossEntropyFlat())\n",
    "#learn_tst = Learner(dls, model_tst, loss_func=LabelSmoothingCrossEntropyFlat())\n",
    "#learn_xcm = Learner(dls, model_xcm, loss_func=LabelSmoothingCrossEntropyFlat())\n",
    "\n",
    "learners = {'LSTM_FCNPlus': learn_lstm_fcn}#, 'LSTMPlus': learn_lstm, 'TST': learn_tst, 'XCMPlus': learn_xcm}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find optimal learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [0.7115873694419861,0.5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['Model Name', 'Rate', 'Accuracy', 'Training Time'])\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "learning_rate = best_params.pop('learning_rate', None)\n",
    "\n",
    "\n",
    "for name, learner in learners.items():\n",
    "    start_time = time.time()\n",
    "    learner.fit_one_cycle(n_epoch=epochs, lr_max=learning_rate)\n",
    "    end_time = time.time()\n",
    "    training_time = round(end_time - start_time, 2)\n",
    "\n",
    "    loss = learner.validate()\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68687a499e0775bfb06d4a0c91954dfe7dcdc7f84c6d272d4d4615fc1c039e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
