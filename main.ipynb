{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data\n",
    "\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from alpaca.data.historical import CryptoHistoricalDataClient, StockHistoricalDataClient\n",
    "\n",
    "#from Data.historical_data import Historical_data\n",
    "import pandas as pd\n",
    "from Preprocessing.preprocessing import preprocessing_improved\n",
    "from Models.LSTM.lightningLSTM import LightningLSTM\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from Preprocessing.dataclasses import StockPriceDataModule, StockDataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = False\n",
    "\n",
    "if new_data:\n",
    "\n",
    "    stocks = [['AAPL'], ['MSFT'], ['GOOG'], ['TSLA'], ['NVDA']]\n",
    "\n",
    "    for stock in stocks:\n",
    "\n",
    "        timeframes = [TimeFrame.Day, TimeFrame.Hour, TimeFrame.Minute]\n",
    "        time_strings = ['Day', 'Hour', 'Minute']\n",
    "\n",
    "        for timeframe, time_string in zip(timeframes, time_strings):\n",
    "\n",
    "            s_type = \"StockBars\"\n",
    "            stock = stock\n",
    "            timeframe = timeframe\n",
    "            start = \"2020-08-20 06:00:00\"\n",
    "            end = \"2021-08-20 06:00:00\"\n",
    "            client = StockHistoricalDataClient(\"PKV7BABG3DGE0GYL137W\", \"af1eQghpVgbyX2lh2T9n2ColmVYXHCWndQbKR3Lr\")\n",
    "            save_csv = True\n",
    "            time_string = time_string\n",
    "\n",
    "            df = Historical_data(s_type = s_type, stock = stock, timeframe = timeframe, start = start, end = end, client = client, save_csv = save_csv , time_string = time_string)\n",
    "\n",
    "else:\n",
    "\n",
    "    df = pd.read_csv('Data\\Stock\\StockBars\\MSFT_Minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sequence', 'label'])\n",
      "torch.Size([64, 100, 8])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = preprocessing_improved(df = df[:int(len(df)*0.1)], lag = 1, sequence_length=100, dif_all=True, train_size=0.9 )\n",
    "data_module = StockPriceDataModule(train_sequence = data_train,  test_sequence= data_test, batch_size=64, num_workers = 4)\n",
    "data_module.setup()\n",
    "\n",
    "for item in data_module.train_dataloader():\n",
    "    print(item.keys())\n",
    "    print(item['sequence'].shape)\n",
    "    print(item['label'].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m learning_model \u001b[39m=\u001b[39m LightningLSTM(input_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, hidden_size \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, num_layers \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(auto_lr_find\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m trainer\u001b[39m.\u001b[39mtune(learning_model)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'learning_rate'"
     ]
    }
   ],
   "source": [
    "learning_model = LightningLSTM(input_size=8, hidden_size = 100, num_layers = 1)\n",
    "trainer = pl.Trainer(auto_lr_find='learning_rate')\n",
    "trainer.tune(learning_model)\n",
    "learning_model.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best_checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"logs/\", name=\"lightninglstm\")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "\n",
    "progressbar = TQDMProgressBar(refresh_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | model     | LSTM    | 44.1 K\n",
      "1 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "44.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "44.1 K    Total params\n",
      "0.176     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84c125994cc43a0ba1e17894fd991c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df10353a405345d3adc7e0deec49e744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6b03a936e04e5dbc55b0b9645b7126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 219: 'val_loss' reached 1.16291 (best 1.16291), saving model to 'C:\\\\Users\\\\lukas\\\\Programmering\\\\Investment AI\\\\Master-Thesis\\\\checkpoints\\\\best_checkpoint-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ba93062a2a4d65a3451e8a3bb059f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 438: 'val_loss' reached 0.85432 (best 0.85432), saving model to 'C:\\\\Users\\\\lukas\\\\Programmering\\\\Investment AI\\\\Master-Thesis\\\\checkpoints\\\\best_checkpoint-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c8f8a1e4c84f3c8eeeab012b4b3190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 657: 'val_loss' reached 0.76936 (best 0.76936), saving model to 'C:\\\\Users\\\\lukas\\\\Programmering\\\\Investment AI\\\\Master-Thesis\\\\checkpoints\\\\best_checkpoint-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9afacd5fff54eb7a5e8f03e322bd66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 876: 'val_loss' reached 0.73478 (best 0.73478), saving model to 'C:\\\\Users\\\\lukas\\\\Programmering\\\\Investment AI\\\\Master-Thesis\\\\checkpoints\\\\best_checkpoint-v1.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b71c2fdddf417d83ef95396a824f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1095: 'val_loss' reached 0.71279 (best 0.71279), saving model to 'C:\\\\Users\\\\lukas\\\\Programmering\\\\Investment AI\\\\Master-Thesis\\\\checkpoints\\\\best_checkpoint-v1.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "model = LightningLSTM(input_size=8, hidden_size = 100, num_layers = 1)\n",
    "trainer = pl.Trainer(max_epochs=5, callbacks=[checkpoint_callback, early_stopping_callback,progressbar], accelerator=\"gpu\", devices=1)\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.freeze()\n",
    "\n",
    "test = StockDataset(data_test)\n",
    "\n",
    "prede = []\n",
    "labels = []\n",
    "\n",
    "for item in test:\n",
    "  sequence = item[\"sequence\"]\n",
    "  label = item['label']\n",
    "\n",
    "  _, output = model(sequence.unsqueeze(dim=0))\n",
    "  prede.append(float(output.numpy()[0]))\n",
    "  labels.append(float(label.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Roaming\\Python\\Python39\\site-packages\\pytorch_lightning\\utilities\\migration\\utils.py:49: PossibleUserWarning: The loaded checkpoint was produced with Lightning v1.9.2, which is newer than your current Lightning version: v1.9.1\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "trained_model = LightningLSTM.load_from_checkpoint(\"checkpoints\\\\best_checkpoint.ckpt\",input_size=8, hidden_size = 100, num_layers = 1)\n",
    "trained_model.freeze()\n",
    "\n",
    "test = StockDataset(data_test)\n",
    "\n",
    "prede = []\n",
    "labels = []\n",
    "\n",
    "for item in test:\n",
    "  sequence = item[\"sequence\"]\n",
    "  label = item['label']\n",
    "\n",
    "  _, output = trained_model(sequence.unsqueeze(dim=0))\n",
    "  prede.append(float(output.numpy()[0]))\n",
    "  labels.append(float(label.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[0;32m      4\u001b[0m count \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcount_nonzero(np\u001b[39m.\u001b[39marray(prede) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39marray(labels) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "count = np.count_nonzero(np.array(prede) * np.array(labels) > 0)\n",
    "\n",
    "accuracy = count / len(prede)\n",
    "\n",
    "# Create a plot of the last 100 values of each time series\n",
    "plt.plot(prede[-100:], label='prede')\n",
    "plt.plot(labels[-100:], label='labels')\n",
    "plt.title(accuracy)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68687a499e0775bfb06d4a0c91954dfe7dcdc7f84c6d272d4d4615fc1c039e3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
