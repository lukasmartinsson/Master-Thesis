{"batch_size": 128, "d_ff": 512, "d_model": 64, "dropout": 0.0, "learning_rate": 0.004756237291260068, "n_heads": 16, "n_layers": 2, "seq_length": 17}